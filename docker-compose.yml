version: '3'

services: 
# build kafka container
  kafka:
    container_name: kafka
    image: apache/kafka:3.7.0  # Use the desired Kafka version
    ports:
      - "9092:9092"  # Expose Kafka port (default 9092)
    networks:
      - lakehouse_network

#build Hadoop
  hadoop-namenode:
    container_name: lakehouse-hadoop-namenode
    image: apache/hadoop:3
    hostname: namenode
    command: ["hdfs", "namenode"]
    ports:
      - 9870:9870
    env_file:
      - ./config
    environment:
      ENSURE_NAMENODE_DIR: "/tmp/hadoop-root/dfs/name"
    networks:
      - lakehouse_network
  hadoop-datanode:
    container_name: lakehouse-hadoop-datanode
    image: apache/hadoop:3
    command: ["hdfs", "datanode"]
    env_file:
      - ./config  
    networks:
      - lakehouse_network    
  
  hadoop-datanode2:
    container_name: lakehouse-hadoop-datanode2
    image: apache/hadoop:3
    command: ["hdfs", "datanode"]
    env_file:
      - ./config
    networks:
      - lakehouse_network

  hadoop-datanode3:
    container_name: lakehouse-hadoop-datanode3
    image: apache/hadoop:3
    command: ["hdfs", "datanode"]
    env_file:
      - ./config
    networks:
      - lakehouse_network

  hadoop-resourcemanager:
    container_name: lakehouse-hadoop-resourcemanager
    image: apache/hadoop:3
    hostname: resourcemanager
    command: ["yarn", "resourcemanager"]
    ports:
        - 8088:8088
    env_file:
      - ./config
    volumes:
      - ./test.sh:/opt/test.sh
    networks:
      - lakehouse_network
  hadoop-nodemanager:
    container_name: lakehouse-hadoop-nodemanager
    image: apache/hadoop:3
    command: ["yarn", "nodemanager"]
    env_file:
      - ./config
    networks:
      - lakehouse_network

    # Add HiveServer2 service
  hiveserver2:
    image: apache/hive:4.0.0
    container_name: hiveserver2
    environment:
      SERVICE_NAME: hiveserver2
    ports:
      - "10000:10000"
      - "10002:10002"
    networks:
      - lakehouse_network

  # Add Metastore service
  metastore:
    image: apache/hive:4.0.0
    container_name: metastore
    environment:
      SERVICE_NAME: metastore
    ports:
      - "9083:9083"
    depends_on:
      - hadoop-namenode
      - hadoop-datanode
    networks:
      - lakehouse_network

# Use Apache Spark 
  spark-master:
    image: apache/spark:latest
    container_name: spark-master
    command: /opt/spark/bin/spark-class org.apache.spark.deploy.master.Master
    ports:
      - "8080:8080"
      - "7077:7077"
    environment:
      - SPARK_MASTER_HOST=spark-master
      - SPARK_MASTER_PORT=7077
    networks:
      - lakehouse_network

  spark-worker:
    image: apache/spark:latest
    container_name: spark-worker
    command: /opt/spark/bin/spark-class org.apache.spark.deploy.worker.Worker spark://spark-master:7077
    environment:
      - SPARK_WORKER_MEMORY=1g
      - SPARK_WORKER_CORES=1
    depends_on:
      - spark-master
    volumes:
      - ./spark_job.py:/spark_job.py
    networks:
      - lakehouse_network

networks:
  lakehouse_network:
    driver: bridge

volumes:
  backend_data:
  kafka_data: